{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb29598",
   "metadata": {},
   "source": [
    "# **Data Mining Introduction**\n",
    "\n",
    "### **Team: Iker Arza & Sofia Fedane**\n",
    "\n",
    "### **Context**\n",
    "\n",
    "This project builds a real-world dataset of bakeries in Ireland using web scraping techniques taught in class. The objective is to collect customer-facing business information from a live online platform, transform it into a structured dataset, and prepare it for further analysis and predictive modelling.\n",
    "\n",
    "### **Dataset Source**\n",
    "\n",
    "The dataset for this project was created exclusively from Yelp.ie, a public review platform that provides rich information on local businesses, including:\n",
    "\n",
    "* Business name\n",
    "* Star rating\n",
    "* Number of reviews\n",
    "* Price range (€ / €€ / €€€)\n",
    "* Categories (e.g., Bakery, Café, Coffee Shop)\n",
    "* Location text\n",
    "* Short customer review snippet\n",
    "\n",
    "Using Selenium and BeautifulSoup, multiple pages of Yelp search results were scraped across several Irish regions.\n",
    "\n",
    "### **Business Motivation**\n",
    "\n",
    "The bakery sector in Ireland spans small artisan bakeries, modern café–bakery hybrids, and larger commercial chains. Understanding what makes some bakeries more successful than others, such as:\n",
    "\n",
    "* higher ratings,\n",
    "* more reviews,\n",
    "* premium or budget pricing,\n",
    "* category specialisation,\n",
    "* regional differences\n",
    "\n",
    "can generate insights valuable to:\n",
    "\n",
    "* **bakery owners** (competitive benchmarking),\n",
    "* **entrepreneurs** (market opportunities),\n",
    "* **marketing teams** (targeting customer preferences),\n",
    "* **industry analysts** (regional demand trends).\n",
    "\n",
    "A high-quality dataset of bakery ratings and attributes enables meaningful exploratory analysis and supports data-driven decision-making in the bakery and hospitality industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eab327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELP_LIMIT = 2500\n",
    "\n",
    "YELP_URLS = {\n",
    "    \"Dublin\":    \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Dublin\",\n",
    "    \"Cork\":      \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Cork\",\n",
    "    \"Galway\":    \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Galway\",\n",
    "    \"Limerick\":  \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Limerick\",\n",
    "    \"Waterford\": \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Waterford\",\n",
    "    \"Kerry\":     \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Kerry\",\n",
    "    \"Louth\":     \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Louth\",\n",
    "    \"Kilkenny\": \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Kilkenny\",\n",
    "    \"Wexford\":  \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Wexford\",\n",
    "    \"Donegal\":  \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Donegal\",\n",
    "    \"Belfast\":  \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Belfast\",\n",
    "    \"Derry\":    \"https://www.yelp.ie/search?find_desc=Bakeries&find_loc=Derry\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53aaea0",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "**Data Source: Yelp**\n",
    "\n",
    "We scrape bakery listings from Yelp.ie across multiple Irish regions, including Dublin, Cork, Galway, Limerick, Waterford, Kerry, and Louth. Yelp provides rich customer-oriented information that complements GoldenPages.\n",
    "\n",
    "The available fields include:\n",
    "- Business name\n",
    "- Star rating\n",
    "- Number of reviews\n",
    "- Price range (€, €€, €€€)\n",
    "- Location / area tags\n",
    "- Business categories (e.g., “Bakery”, “Café”, “Patisserie”)\n",
    "- Short review snippet visible in search results\n",
    "\n",
    "\n",
    "In this part of the project, we:\n",
    "- Loop through each selected Irish region.\n",
    "- Load the search results page for bakeries.\n",
    "- Scroll to dynamically load all visible listings.\n",
    "- Parse each listing card using BeautifulSoup.\n",
    "- Extract key customer-focused features such as rating, review count, price range, categories, and review snippet.\n",
    "- Click the “Next” button until no further pages are available or until the combined total dataset reaches 1,500 rows.\n",
    "\n",
    "These rows form the second half of the dataset and complement the GoldenPages business information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd2749",
   "metadata": {},
   "source": [
    "## Yelp Scraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18750391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yelp(max_rows=1200, max_pages_per_region=40):\n",
    "    rows = []\n",
    "    \n",
    "    for region_label, base_url in YELP_URLS.items():\n",
    "        print(f\"\\nYelp region: {region_label}\")\n",
    "\n",
    "        for page_number in range(max_pages_per_region):\n",
    "\n",
    "            if len(rows) >= max_rows:\n",
    "                print(\"Reached Yelp row limit:\", len(rows))\n",
    "                return rows\n",
    "\n",
    "            # Build page URL\n",
    "            page_url = base_url if page_number == 0 else base_url + f\"&start={page_number * 10}\"\n",
    "            print(f\"  Page {page_number + 1}: {page_url}\")\n",
    "\n",
    "            driver.get(page_url)\n",
    "            time.sleep(2.5)\n",
    "\n",
    "            # Scroll load\n",
    "            try:\n",
    "                body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "                for _ in range(3):\n",
    "                    body.send_keys(Keys.END)\n",
    "                    time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            cards = soup.find_all(\"div\", attrs={\"data-testid\": \"serp-ia-card\"})\n",
    "\n",
    "            if not cards:\n",
    "                print(\"  No more results for this region.\")\n",
    "                break\n",
    "\n",
    "            for card in cards:\n",
    "                if len(rows) >= max_rows:\n",
    "                    break\n",
    "\n",
    "                name_tag    = card.find(\"a\", class_=\"y-css-1x1e1r2\")\n",
    "                rating_tag  = card.find(\"span\", class_=\"y-css-f73en8\")\n",
    "                review_tag  = card.find(\"span\", class_=\"y-css-1vi7y4e\")\n",
    "                loc_tag     = card.find(\"span\", class_=\"y-css-wpsy4m\")\n",
    "                price_tag   = card.find(\"span\", class_=\"y-css-1y784sg\")\n",
    "                snippet_tag = card.find(\"p\", class_=\"y-css-oyr8zn\")\n",
    "\n",
    "                categories = \", \".join([c.get_text(strip=True) for c in card.find_all(\"p\")])\n",
    "\n",
    "                rows.append({\n",
    "                    \"source\": \"Yelp\",\n",
    "                    \"region\": region_label,\n",
    "                    \"name\": name_tag.get_text(strip=True) if name_tag else None,\n",
    "                    \"rating_raw\": rating_tag.get_text(strip=True) if rating_tag else None,\n",
    "                    \"review_count_raw\": review_tag.get_text(strip=True) if review_tag else None,\n",
    "                    \"location\": loc_tag.get_text(strip=True) if loc_tag else None,\n",
    "                    \"price_range\": price_tag.get_text(strip=True) if price_tag else None,\n",
    "                    \"categories\": categories,\n",
    "                    \"snippet\": snippet_tag.get_text(\" \", strip=True)[:200] if snippet_tag else None\n",
    "                })\n",
    "\n",
    "            print(\"    Total Yelp collected:\", len(rows))\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING YELP SCRAPING ---\")\n",
    "yelp_rows = scrape_yelp(max_rows=YELP_LIMIT)\n",
    "print(\"Final Yelp count:\", len(yelp_rows))\n",
    "\n",
    "# --------- Convert to DataFrame ---------\n",
    "df = pd.DataFrame(yelp_rows)\n",
    "\n",
    "# --------- Deduplicate based on name + region + location ---------\n",
    "df = df.drop_duplicates(subset=[\"name\", \"region\", \"location\"], keep=\"first\")\n",
    "\n",
    "# --------- Save dataset ---------\n",
    "df.to_csv(\"../data/dataProject.csv\", index=False)\n",
    "print(\"\\nDataset saved to ../data/dataProject.csv\")\n",
    "\n",
    "# --------- Show CSV size ---------\n",
    "size_mb = os.path.getsize(\"../data/dataProject.csv\")/(1024*1024)\n",
    "print(f\"CSV size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326158b",
   "metadata": {},
   "source": [
    "---\n",
    "# **Data Mining Summary, Issues & Limitations**\n",
    "\n",
    "### **Project Overview**\n",
    "\n",
    "The data mining phase involved me, Sofia, building a dataset of Irish bakeries through automated web scraping of Yelp.ie.\n",
    "\n",
    "We chose this topic as I really love to eat a variety of desserts, as a customer, but I'm also picky and would like to know which places are best to choose from.\n",
    "\n",
    "The process required anti-bot protections as you would find in the AI use declaration, while collecting useful business intelligence data.\n",
    "\n",
    "The scraping procedure gathered ~1,519 bakery listings across multiple Irish regions before deduplicating to 1,488.\n",
    "\n",
    "---\n",
    "\n",
    "## **Technical Implementation & Methodology**\n",
    "\n",
    "### **Scraping Architecture**\n",
    "The data collection used a two-layer approach, same from class:\n",
    "- **Selenium WebDriver**: Dynamic content loading, JavaScript execution, pagination\n",
    "- **BeautifulSoup**: HTML parsing, structured data extraction\n",
    "- **Pandas**: Data storage and transformation\n",
    "\n",
    "### **Regional Coverage Strategy**\n",
    "Geographical sampling across 12 Irish regions:\n",
    "- **Big / Urban Centers**: Dublin, Cork, Galway, Belfast\n",
    "- **Regional:**: Kerry, Louth, Kilkenny, Wexford, Donegal, Limerick, Waterford, Derry\n",
    "\n",
    "We did this becauae we wanted to do it in a stratified way to ensure the market representtion was as broad as possible rather than just urban.\n",
    "\n",
    "\n",
    "### **Data Extraction Attributes**\n",
    "8 key business attributes:\n",
    "- Business identity (name, region)\n",
    "- Performance metrics (star rating, review count)\n",
    "- Market positioning (price range, categories)\n",
    "- Customer insights (review snippets, location context)\n",
    "\n",
    "---\n",
    "\n",
    "## **Technical Challenges & Solutions**\n",
    "\n",
    "### **1. Dynamic Content Management**\n",
    "**Challenge**: Yelp relies heavily on JS rendering so traditional scraping methods captured empty page templates when we started.\n",
    "\n",
    "**Solution**: Implemented Selenium with planned scrolling and loading delays to get complete content rendering before parsing.\n",
    "\n",
    "### **2. HTML Structure Volatility**\n",
    "**Challenge**: Yelp randomly changes CSS classes and that breaks selector-based scraping.\n",
    "\n",
    "**Solution**:\n",
    "- 'data-testid' attributes\n",
    "- Structural element relationships\n",
    "- Fallback selection strategies\n",
    "\n",
    "### **3. Anti-Bot Countermeasures**\n",
    "**Challenge**: Yelp's bot detection triggered CAPTCHAs and IP rate limiting during intensive scraping sessions.\n",
    "\n",
    "**Mitigation Strategies**:\n",
    "- Randomized request delays between 2.5-5 seconds\n",
    "- Used session persistence to maintain browser state\n",
    "- Incremental saving to keep progress during interruptions\n",
    "- Error handling to continue when the website blocks that page\n",
    "\n",
    "### **4. Data Consistency Issues**\n",
    "**Challenge**: Inconsistent field availability across listings actually reflects real-world business profile variations.\n",
    "\n",
    "**Approach**: Accepted natural missingness patterns as authentic market characteristics rather than a failure in scraping.\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Quality Assessment**\n",
    "\n",
    "### **Completeness Analysis**\n",
    "- **Price ranges**: 940 missing (Which is ~63.2% and is common for new/unpriced establishments)\n",
    "- **Ratings**: 440 missing (Which is ~29.6% and can be new businesses without reviews)\n",
    "- **Review counts**: 516 missing (Which is ~34.7%, consistent with business activity patterns)\n",
    "\n",
    "These patterns shows genuine business characteristics rather than collection errors.\n",
    "\n",
    "### **Data Capture Issues Identified**\n",
    "- **78 entries** with business hours incorrectly captured as ratings\n",
    "- **272 entries** with mixed currency formats (€, $, £) from Yelp's international platform\n",
    "- **10 different price formats** requiring standardization\n",
    "\n",
    "### **Geographical Distribution**\n",
    "- **High density**: Dublin, Cork (high population)\n",
    "- **Medium density**: Galway, Belfast (urban tourism)\n",
    "- **Lower density**: Regional areas like our Louth county (authentic market distribution)\n",
    "\n",
    "### **Duplicate Management**\n",
    "Implemented deduplication using composite keys (name + region + location) to keep data uniqueness but preserving legitimate chain locations across regions like The Home Bakery.\n",
    "\n",
    "---\n",
    "\n",
    "## **Methodological Strengths**\n",
    "\n",
    "### **Data Integrity**\n",
    "- **Type preservation**: Kept original data formats during extraction\n",
    "- **Relationship consistency**: Kept business attribute relationships\n",
    "- **Metadata tracking**: Included source and collection timing context\n",
    "\n",
    "### **Ethical Compliance**\n",
    "- Respectful request intervals avoided service disruption\n",
    "- Data usage aligned with academic research purposes\n",
    "- Transparent methodology documentation\n",
    "\n",
    "---\n",
    "\n",
    "## **Limitations & Boundary Conditions**\n",
    "\n",
    "### **Technical Constraints**\n",
    "1. **Rate Limiting**: Collection speed limited by anti-bot protections\n",
    "2. **Content Stability**: Periodic Yelp UI changes required me to update the selector\n",
    "3. **Regional Biases**: Listing availability reflects Yelp's user base distribution\n",
    "\n",
    "### **Market Representation**\n",
    "- **Coverage**: Yelp's Irish businesses\n",
    "- **Recency**: Current as of collection date (November 2025)\n",
    "\n",
    "---\n",
    "\n",
    "## **Strategic Value & Applications**\n",
    "1. **Competitive Intelligence**: Regional benchmarking and positioning analysis\n",
    "2. **Consumer Insights**: Rating patterns and review sentiment trends\n",
    "3. **Market Gaps**: Geographical and categorical opportunity identification\n",
    "4. **Quality Correlations**: Relationship between price, ratings, and business attributes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb44137",
   "metadata": {},
   "source": [
    "\n",
    "# **AI Use Declaration (Correct + Safe Version)**\n",
    "\n",
    "### **AI Use Declaration**\n",
    "\n",
    "Generative AI (ChatGPT) was used only during the Data Mining stage of the project.\n",
    "AI was not used for Data Cleaning, EDA, Feature Engineering, Modelling, or Conclusions.\n",
    "\n",
    "The purpose of AI use was to troubleshoot issues encountered during web scraping, specifically:\n",
    "\n",
    "* being temporarily IP-blocked by GoldenPages\n",
    "* receiving bot-detection/CAPTCHA pages from Yelp\n",
    "* selectors breaking due to frequent HTML changes\n",
    "* deciding whether to rescrape and how many listings to target\n",
    "\n",
    "The AI was used to diagnose technical scraping errors and suggest corrective actions such as using a different network IP, reviewing CSS selectors, and adjusting scraping volume.\n",
    "All scraping code and dataset collection were authored and executed by me.\n",
    "\n",
    "---\n",
    "\n",
    "### **Technologies Used**\n",
    "\n",
    "* ChatGPT (OpenAI)\n",
    "\n",
    "---\n",
    "\n",
    "### **Prompts Provided (Summarised)**\n",
    "\n",
    "Examples of the types of prompts I submitted:\n",
    "\n",
    "* *“GoldenPages isn’t loading, was my IP blocked?”*\n",
    "* *“Even when I visit the page normally I get CAPTCHA, what does that mean?”*\n",
    "* *“I switched to mobile hotspot and scraping works again, is this due to IP banning?”*\n",
    "* *“I scraped 852 rows. Should I scrape more to get a stronger modelling dataset?”*\n",
    "* *“My scraper returned 0 rows, is this due to IP ban or did selectors break?”*\n",
    "\n",
    "---\n",
    "\n",
    "### **Outputs Received (Summarised)**\n",
    "\n",
    "ChatGPT provided:\n",
    "\n",
    "* confirmation that GoldenPages had likely IP-blocked my home network\n",
    "* an explanation that switching to mobile data bypassed the block\n",
    "* warnings about CAPTCHA lockout when scraping Yelp repeatedly\n",
    "* advice that datasets around 1,200-2,000 rows improve modelling quality\n",
    "* identification that “0 rows scraped” was caused by selector break, not IP ban\n",
    "* guidance to pause scraping to avoid extending a block\n",
    "\n",
    "No AI-generated code was copied into the notebook, and no analysis, explanations, or modelling were AI-produced.\n",
    "\n",
    "---\n",
    "\n",
    "### **How AI Output Was Used**\n",
    "\n",
    "* Used informationally to understand why the scraper failed\n",
    "* Used to help decide whether to retry scraping or adjust the number of pages\n",
    "* Used to confirm that certain errors (0 rows, CAPTCHA page) were expected results of bot detection\n",
    "\n",
    "AI output was not inserted directly into the project files and was ot used for any analysis or modelling stages.\n",
    "\n",
    "---\n",
    "\n",
    "### **Declaration**\n",
    "\n",
    "I confirm that generative AI was used only for troubleshooting the Data Mining stage as described above, and no AI-generated content appears in the analysis, data cleaning, EDA, modelling, or conclusions.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
